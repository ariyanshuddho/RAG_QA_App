Generative AI & Chatbot Development: Python Assignment Objective Develop a smart Retrieval-Augmented Generation (RAG) API that can answer questions based on information extracted from any document type â€” including PDFs, Word files, images (OCR), .txt, and even small databases. Bonus points for supporting image-based questions (e.g., diagrams, scanned docs). What It Should Do Create a FastAPI application that: â— Accepts any document type as input (.pdf, .docx, .txt, .jpg, .png, .csv, SQLite .db,
(.pdf, .docx, .txt, .jpg, .png, .csv, SQLite .db, etc.) â— Extracts and preprocesses relevant content (text and/or image-based) â— Embeds content and stores in a vector store like FAISS â— Accepts text or image-based questions â— Performs similarity search and constructs a context prompt â— Sends the prompt to an LLM (OpenAI or similar) â— Returns a final answer via API response Core Tasks 1. Document Ingestion â— Accept file uploads or a path/URL to a document. â— Handle: â—‹ .pdf via PyMuPDF or pdfplumb
document. â— Handle: â—‹ .pdf via PyMuPDF or pdfplumber â—‹ .docx via python-docx â—‹ .txt directly â—‹ .jpg, .png, or scanned .pdf using OCR (pytesseract) â—‹ .csv or .db using pandas/sqlite3 â— Convert all content into clean, meaningful chunks of text (with overlap). 2. Embeddings + Storage â— Use OpenAI embeddings (or SentenceTransformers) to generate embeddings. â— Store them in FAISS or ChromaDB. â— Save metadata (e.g., filename, page, chunk index). 3. Question Endpoint Expose a POST /query endpoint like:
stion Endpoint Expose a POST /query endpoint like: { "question": "What does the invoice say about payment terms?", "image_base64": "optional_base64_encoded_image"} â— Perform OCR on image (if provided). â— Perform vector search based on the question. â— Construct context + question prompt. â— Send to LLM (OpenAI, Claude, etc.) and return a clean answer. 4. Bonus Features (Optional but Impressive) â— Image+text multimodal prompt support using GPT-4 Vision or Claude â— Handle multi-document querying â— A
ion or Claude â— Handle multi-document querying â— Add /upload endpoint to upload files and return a file_id â— Use LangChain for chaining and orchestration â— Add file-type icons and metadata to response â— Containerize using Docker â— Minimal web frontend using Streamlit ğŸ§ª Sample Workflow 1. Upload File: Uploads a .pdf, .docx, or .jpg via /upload 2. Ask a Question: â—‹ â€œWhat are the product specs mentioned in the attached PDF?â€ â—‹ â€œWhat is written in this image?â€ (image passed in base64) 3. API Returns
is image?â€ (image passed in base64) 3. API Returns: â—‹ Context â—‹ Final Answer â—‹ Source info (e.g., page 3 of invoice.pdf) ğŸš€ Technologies You May Use â— Python, FastAPI, async/await â— FAISS or ChromaDB â— OCR: pytesseract, easyocr â— Document Parsers: pdfplumber, docx, pandas, etc. â— Embeddings: OpenAI, HuggingFace (e.g., all-MiniLM) â— LLM API: OpenAI, Claude, HuggingFace Hub â— Docker (bonus) ğŸ“¤ Submission â— GitHub repo or ZIP with: â—‹ Source code â—‹ Sample files â—‹ README.md with: â–  Instructions â–  API u
ple files â—‹ README.md with: â–  Instructions â–  API usage â–  Environment setupâ–  Sample .env â— Deployed version (optional but bonus) Evaluation Criteria Criteria Weight File parsing & preprocessing 20% Vector search + RAG flow 20% Image OCR handling 15% API design & FastAPI usage 15% Prompt engineering & LLM response 15% Bonus (Docker, LangChain, UI, etc.) 15%
